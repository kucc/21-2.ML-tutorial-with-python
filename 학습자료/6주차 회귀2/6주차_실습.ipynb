{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "experienced-republican",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "excited-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "bostonDF = pd.DataFrame(boston.data , columns = boston.feature_names)\n",
    "bostonDF['PRICE'] = boston.target\n",
    "\n",
    "y_target_boston = bostonDF['PRICE']\n",
    "X_data_boston = bostonDF.drop(['PRICE'],axis=1,inplace=False)\n",
    "\n",
    "X_train_boston , X_test_boston , y_train_boston , y_test_boston = train_test_split(X_data_boston , y_target_boston ,\n",
    "                                                                                   test_size=0.3, random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sacred-sigma",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 folds 의 개별 RMSE scores :  [3.38  4.929 5.305 8.637 5.34 ]\n",
      " 5 folds 의 평균 RMSE : 5.518 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "ridge = Ridge(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(ridge, X_data_boston, y_target_boston, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "naval-communication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0 일 때 5 folds 의 평균 RMSE : 5.829 \n",
      "alpha 0.1 일 때 5 folds 의 평균 RMSE : 5.788 \n",
      "alpha 1 일 때 5 folds 의 평균 RMSE : 5.653 \n",
      "alpha 10 일 때 5 folds 의 평균 RMSE : 5.518 \n",
      "alpha 100 일 때 5 folds 의 평균 RMSE : 5.330 \n"
     ]
    }
   ],
   "source": [
    "# alpha값 하이퍼파라미터튜닝\n",
    "alphas = [0 , 0.1 , 1 , 10 , 100]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(ridge, X_data_boston, y_target_boston, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "answering-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0 일 때 회귀계수 :\n",
      "RM          3.809865\n",
      "CHAS        2.686734\n",
      "RAD         0.306049\n",
      "ZN          0.046420\n",
      "INDUS       0.020559\n",
      "B           0.009312\n",
      "AGE         0.000692\n",
      "TAX        -0.012335\n",
      "CRIM       -0.108011\n",
      "LSTAT      -0.524758\n",
      "PTRATIO    -0.952747\n",
      "DIS        -1.475567\n",
      "NOX       -17.766611\n",
      "dtype: float64\n",
      "\n",
      "alpha 0.1 일 때 회귀계수 :\n",
      "RM          3.818233\n",
      "CHAS        2.670019\n",
      "RAD         0.303515\n",
      "ZN          0.046572\n",
      "INDUS       0.015999\n",
      "B           0.009368\n",
      "AGE        -0.000269\n",
      "TAX        -0.012421\n",
      "CRIM       -0.107474\n",
      "LSTAT      -0.525966\n",
      "PTRATIO    -0.940759\n",
      "DIS        -1.459626\n",
      "NOX       -16.684645\n",
      "dtype: float64\n",
      "\n",
      "alpha 1 일 때 회귀계수 :\n",
      "RM          3.854000\n",
      "CHAS        2.552393\n",
      "RAD         0.290142\n",
      "ZN          0.047443\n",
      "B           0.009673\n",
      "AGE        -0.005415\n",
      "INDUS      -0.008805\n",
      "TAX        -0.012912\n",
      "CRIM       -0.104595\n",
      "LSTAT      -0.533343\n",
      "PTRATIO    -0.876074\n",
      "DIS        -1.372654\n",
      "NOX       -10.777015\n",
      "dtype: float64\n",
      "\n",
      "alpha 10 일 때 회귀계수 :\n",
      "RM         3.702272\n",
      "CHAS       1.952021\n",
      "RAD        0.279596\n",
      "ZN         0.049579\n",
      "B          0.010037\n",
      "AGE       -0.010707\n",
      "TAX       -0.013993\n",
      "INDUS     -0.042962\n",
      "CRIM      -0.101435\n",
      "LSTAT     -0.559366\n",
      "PTRATIO   -0.797945\n",
      "DIS       -1.248808\n",
      "NOX       -2.371619\n",
      "dtype: float64\n",
      "\n",
      "alpha 100 일 때 회귀계수 :\n",
      "RM         2.334536\n",
      "CHAS       0.638335\n",
      "RAD        0.315358\n",
      "ZN         0.054496\n",
      "B          0.009393\n",
      "AGE        0.001212\n",
      "TAX       -0.015856\n",
      "INDUS     -0.052826\n",
      "CRIM      -0.102202\n",
      "NOX       -0.262847\n",
      "LSTAT     -0.660764\n",
      "PTRATIO   -0.829218\n",
      "DIS       -1.153390\n",
      "dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for alpha in alphas :\n",
    "    ridge = Ridge(alpha = alpha)\n",
    "    ridge.fit(X_data_boston , y_target_boston)\n",
    "    \n",
    "    coeff = pd.Series(data=ridge.coef_, index=X_data_boston.columns)    \n",
    "    print('alpha {0} 일 때 회귀계수 :'.format(alpha))\n",
    "    print(coeff.sort_values(ascending=False))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-secondary",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "certain-madonna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5 folds 의 개별 RMSE scores :  [5.271 6.812 8.962 7.846 4.038]\n",
      " 5 folds 의 평균 RMSE : 6.586 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso = Lasso(alpha = 10)\n",
    "neg_mse_scores = cross_val_score(lasso, X_data_boston, y_target_boston, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "rmse_scores  = np.sqrt(-1 * neg_mse_scores)\n",
    "avg_rmse = np.mean(rmse_scores)\n",
    "print(' 5 folds 의 개별 RMSE scores : ', np.round(rmse_scores,3))\n",
    "print(' 5 folds 의 평균 RMSE : {0:.3f} '.format(avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "static-appliance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.07 일 때 5 folds 의 평균 RMSE : 5.612 \n",
      "alpha 0.1 일 때 5 folds 의 평균 RMSE : 5.615 \n",
      "alpha 0.5 일 때 5 folds 의 평균 RMSE : 5.669 \n",
      "alpha 1 일 때 5 folds 의 평균 RMSE : 5.776 \n",
      "alpha 3 일 때 5 folds 의 평균 RMSE : 6.189 \n"
     ]
    }
   ],
   "source": [
    "# alpha값 하이퍼파라미터튜닝\n",
    "alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(lasso, X_data_boston, y_target_boston, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "common-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.789725</td>\n",
       "      <td>3.703202</td>\n",
       "      <td>2.498212</td>\n",
       "      <td>0.949811</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.434343</td>\n",
       "      <td>0.955190</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.274707</td>\n",
       "      <td>0.277451</td>\n",
       "      <td>0.264206</td>\n",
       "      <td>0.061864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.049059</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>0.049165</td>\n",
       "      <td>0.037231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.010249</td>\n",
       "      <td>0.009469</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.006510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.011706</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>0.003604</td>\n",
       "      <td>0.020910</td>\n",
       "      <td>0.042495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014290</td>\n",
       "      <td>-0.014570</td>\n",
       "      <td>-0.015442</td>\n",
       "      <td>-0.015212</td>\n",
       "      <td>-0.008602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.042120</td>\n",
       "      <td>-0.036619</td>\n",
       "      <td>-0.005253</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.098193</td>\n",
       "      <td>-0.097894</td>\n",
       "      <td>-0.083289</td>\n",
       "      <td>-0.063437</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.560431</td>\n",
       "      <td>-0.568769</td>\n",
       "      <td>-0.656290</td>\n",
       "      <td>-0.761115</td>\n",
       "      <td>-0.807679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.765107</td>\n",
       "      <td>-0.770654</td>\n",
       "      <td>-0.758752</td>\n",
       "      <td>-0.722966</td>\n",
       "      <td>-0.265072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.176583</td>\n",
       "      <td>-1.160538</td>\n",
       "      <td>-0.936605</td>\n",
       "      <td>-0.668790</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.789725   3.703202   2.498212  0.949811  0.000000\n",
       "CHAS       1.434343   0.955190   0.000000  0.000000  0.000000\n",
       "RAD        0.270936   0.274707   0.277451  0.264206  0.061864\n",
       "ZN         0.049059   0.049211   0.049544  0.049165  0.037231\n",
       "B          0.010248   0.010249   0.009469  0.008247  0.006510\n",
       "NOX       -0.000000  -0.000000  -0.000000 -0.000000  0.000000\n",
       "AGE       -0.011706  -0.010037   0.003604  0.020910  0.042495\n",
       "TAX       -0.014290  -0.014570  -0.015442 -0.015212 -0.008602\n",
       "INDUS     -0.042120  -0.036619  -0.005253 -0.000000 -0.000000\n",
       "CRIM      -0.098193  -0.097894  -0.083289 -0.063437 -0.000000\n",
       "LSTAT     -0.560431  -0.568769  -0.656290 -0.761115 -0.807679\n",
       "PTRATIO   -0.765107  -0.770654  -0.758752 -0.722966 -0.265072\n",
       "DIS       -1.176583  -1.160538  -0.936605 -0.668790 -0.000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame()\n",
    "for alpha in alphas :\n",
    "    lasso = Lasso(alpha = alpha)\n",
    "    lasso.fit(X_data_boston , y_target_boston)\n",
    "    \n",
    "    coeff = pd.Series(data=lasso.coef_, index=X_data_boston.columns)\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    \n",
    "sort_column = 'alpha:'+str(alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-arcade",
   "metadata": {},
   "source": [
    "## ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-albany",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha 0.07 일 때 5 folds 의 평균 RMSE : 5.542 \n",
      "alpha 0.1 일 때 5 folds 의 평균 RMSE : 5.526 \n",
      "alpha 0.5 일 때 5 folds 의 평균 RMSE : 5.467 \n",
      "alpha 1 일 때 5 folds 의 평균 RMSE : 5.597 \n",
      "alpha 3 일 때 5 folds 의 평균 RMSE : 6.068 \n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "alphas = [0.07, 0.1, 0.5, 1, 3]\n",
    "\n",
    "# alphas list 값을 iteration하면서 alpha에 따른 평균 rmse 구함.\n",
    "for alpha in alphas :\n",
    "    elsnet = ElasticNet(alpha = alpha, l1_ratio=0.7)\n",
    "    \n",
    "    #cross_val_score를 이용하여 5 fold의 평균 RMSE 계산\n",
    "    neg_mse_scores = cross_val_score(elsnet, X_data_boston, y_target_boston, scoring=\"neg_mean_squared_error\", cv = 5)\n",
    "    avg_rmse = np.mean(np.sqrt(-1 * neg_mse_scores))\n",
    "    print('alpha {0} 일 때 5 folds 의 평균 RMSE : {1:.3f} '.format(alpha,avg_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "representative-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha:0.07</th>\n",
       "      <th>alpha:0.1</th>\n",
       "      <th>alpha:0.5</th>\n",
       "      <th>alpha:1</th>\n",
       "      <th>alpha:3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>3.574162</td>\n",
       "      <td>3.414154</td>\n",
       "      <td>1.918419</td>\n",
       "      <td>0.938789</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CHAS</th>\n",
       "      <td>1.330724</td>\n",
       "      <td>0.979706</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RAD</th>\n",
       "      <td>0.278880</td>\n",
       "      <td>0.283443</td>\n",
       "      <td>0.300761</td>\n",
       "      <td>0.289299</td>\n",
       "      <td>0.146846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>0.050107</td>\n",
       "      <td>0.050617</td>\n",
       "      <td>0.052878</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>0.038268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B</th>\n",
       "      <td>0.010122</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.009114</td>\n",
       "      <td>0.008320</td>\n",
       "      <td>0.007020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGE</th>\n",
       "      <td>-0.010116</td>\n",
       "      <td>-0.008276</td>\n",
       "      <td>0.007760</td>\n",
       "      <td>0.020348</td>\n",
       "      <td>0.043446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAX</th>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>-0.016046</td>\n",
       "      <td>-0.016218</td>\n",
       "      <td>-0.011417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>-0.044855</td>\n",
       "      <td>-0.042719</td>\n",
       "      <td>-0.023252</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>-0.099468</td>\n",
       "      <td>-0.099213</td>\n",
       "      <td>-0.089070</td>\n",
       "      <td>-0.073577</td>\n",
       "      <td>-0.019058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.175072</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>-0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTAT</th>\n",
       "      <td>-0.574822</td>\n",
       "      <td>-0.587702</td>\n",
       "      <td>-0.693861</td>\n",
       "      <td>-0.760457</td>\n",
       "      <td>-0.800368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PTRATIO</th>\n",
       "      <td>-0.779498</td>\n",
       "      <td>-0.784725</td>\n",
       "      <td>-0.790969</td>\n",
       "      <td>-0.738672</td>\n",
       "      <td>-0.423065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIS</th>\n",
       "      <td>-1.189438</td>\n",
       "      <td>-1.173647</td>\n",
       "      <td>-0.975902</td>\n",
       "      <td>-0.725174</td>\n",
       "      <td>-0.031208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         alpha:0.07  alpha:0.1  alpha:0.5   alpha:1   alpha:3\n",
       "RM         3.574162   3.414154   1.918419  0.938789  0.000000\n",
       "CHAS       1.330724   0.979706   0.000000  0.000000  0.000000\n",
       "RAD        0.278880   0.283443   0.300761  0.289299  0.146846\n",
       "ZN         0.050107   0.050617   0.052878  0.052136  0.038268\n",
       "B          0.010122   0.010067   0.009114  0.008320  0.007020\n",
       "AGE       -0.010116  -0.008276   0.007760  0.020348  0.043446\n",
       "TAX       -0.014522  -0.014814  -0.016046 -0.016218 -0.011417\n",
       "INDUS     -0.044855  -0.042719  -0.023252 -0.000000 -0.000000\n",
       "CRIM      -0.099468  -0.099213  -0.089070 -0.073577 -0.019058\n",
       "NOX       -0.175072  -0.000000  -0.000000 -0.000000 -0.000000\n",
       "LSTAT     -0.574822  -0.587702  -0.693861 -0.760457 -0.800368\n",
       "PTRATIO   -0.779498  -0.784725  -0.790969 -0.738672 -0.423065\n",
       "DIS       -1.189438  -1.173647  -0.975902 -0.725174 -0.031208"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coeff_df = pd.DataFrame()\n",
    "for alpha in alphas :\n",
    "    elsnet = ElasticNet(alpha = alpha, l1_ratio=0.7)\n",
    "    elsnet.fit(X_data_boston , y_target_boston)\n",
    "    \n",
    "    coeff = pd.Series(data=elsnet.coef_, index=X_data_boston.columns)\n",
    "    colname='alpha:'+str(alpha)\n",
    "    coeff_df[colname] = coeff\n",
    "    \n",
    "sort_column = 'alpha:'+str(alphas[0])\n",
    "coeff_df.sort_values(by=sort_column, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-hunter",
   "metadata": {},
   "source": [
    "## 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "exceptional-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dressed-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train_cancer , X_test_cancer, y_train_cancer , y_test_cancer = train_test_split(data_scaled, cancer.target, \n",
    "                                                                                  test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "operational-salon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.977\n",
      "roc_auc: 0.972\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "# 로지스틱 회귀를 이용하여 학습 및 예측 수행. \n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train_cancer, y_train_cancer)\n",
    "lr_preds = lr_clf.predict(X_test_cancer)\n",
    "\n",
    "# accuracy와 roc_auc 측정\n",
    "print('accuracy: {:0.3f}'.format(accuracy_score(y_test_cancer, lr_preds)))\n",
    "print('roc_auc: {:0.3f}'.format(roc_auc_score(y_test_cancer , lr_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "funky-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최적 하이퍼 파라미터:{'C': 1, 'penalty': 'l2'}, 최적 평균 정확도:0.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\eunai\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.94555834        nan 0.97364708        nan 0.97539218        nan\n",
      " 0.97539218        nan 0.97011974        nan 0.96661097        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params={'penalty':['l2', 'l1'],\n",
    "        'C':[0.01, 0.1, 1, 1, 5, 10]}\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring='accuracy', cv=3 )\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print('최적 하이퍼 파라미터:{0}, 최적 평균 정확도:{1:.3f}'.format(grid_clf.best_params_, \n",
    "                                                  grid_clf.best_score_))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-jersey",
   "metadata": {},
   "source": [
    "## 트리기반 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "caroline-donor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "dt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\n",
    "rf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\n",
    "gb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\n",
    "xgb_reg = XGBRegressor(n_estimators=1000)\n",
    "lgb_reg = LGBMRegressor(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cooked-disease",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor 회귀 모델의 rmse 값: 3.1666749686184286\n",
      "RandomForestRegressor 회귀 모델의 rmse 값: 2.699553665788792\n",
      "GradientBoostingRegressor 회귀 모델의 rmse 값: 2.601457572082426\n",
      "XGBRegressor 회귀 모델의 rmse 값: 2.6291810544326335\n",
      "LGBMRegressor 회귀 모델의 rmse 값: 2.829125194085535\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\n",
    "\n",
    "for model in models:\n",
    "    model.fit(X_train_boston, y_train_boston)\n",
    "    y_pred = model.predict(X_test_boston)\n",
    "    mse = mean_squared_error(y_pred, y_test_boston)\n",
    "    rmse = mse**(1/2)\n",
    "    \n",
    "    print(model.__class__.__name__,'회귀 모델의 rmse 값:', rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
